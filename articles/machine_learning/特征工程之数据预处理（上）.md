
> 2019年第 14 篇文章，总第 38 篇文章

> 本文大约 3600 字，阅读大约需要 10 分钟

机器学习入门系列（2）--如何构建一个完整的机器学习项目，第三篇！

该系列的前两篇文章：

- [机器学习入门系列(2)--如何构建一个完整的机器学习项目(一)](https://mp.weixin.qq.com/s/nMG5Z3CPdwhg4XQuMbNqbw)
- [机器学习数据集的获取和测试集的构建方法](https://mp.weixin.qq.com/s/HxGO7mhxeuXrloN61sDGmg)

分别介绍了确定项目终极目标、选择损失函数、获取数据以及构建测试集，接下来在进入选择算法和训练模型之前，一个很重要的步骤就是特征工程，它包括了对数据的预处理、特征提取、特征分析以及特征构建等几个步骤，可以说能否训练一个好的模型，除了选择合适的算法，准备好数据也是非常关键的！

由于篇幅问题，所以这篇文章先介绍如何处理缺失值和图片数据扩充的问题，下一篇文章会介绍处理异常值和类别不平衡的问题。

---
### 3 特征工程

何为特征工程呢？顾名思义，就是**对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。**

本质上讲，**特征工程是一个表示和展现数据的过程**；实际工作中，特征工程的目的是**去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系。**

特征工程的重要性有以下几点：

1. **特征越好，灵活性越强**。好的特征的灵活性在于它允许你选择不复杂的模型，同时运行速度也更快，也更容易和维护。
2. **特征越好，构建的模型越简单**。好的特征可以在参数不是最优的情况，依然得到很好的性能，减少调参的工作量和时间，也就可以大大降低模型复杂度。
3. **特征越好，模型的性能越出色**。特征工程的目的本来就是为了提升模型的性能。

#### 3.1 数据预处理

首先需要对数据进行预处理，一般常用的两种数据类型：

1. **结构化数据**。结构化数据可以看作是关系型数据库的一张表，每列都有清晰的定义，包含了数值型和类别型两种基本类型；每一行数据表示一个样本的信息。
2. **非结构化数据**。主要是文本、图像、音频和视频数据，其包含的信息无法用一个简单的数值表示，也没有清晰的类别定义，并且每个数据的大小互不相同。

这里主要介绍结构化数据和图像数据两种数据的数据预处理方法。

##### 3.1.1 处理缺失值

数据的缺失主要包括**记录的缺失和记录中某个字段信息的缺失**，两者都会造成分析结果的不准确。

###### **缺失值产生的原因**

- 信息暂时无法获取，或者获取信息的代价太大。
- 信息被遗漏，人为的输入遗漏或者数据采集设备的遗漏。
- 属性不存在，在某些情况下，缺失值并不意味着数据有错误，对一些对象来说某些属性值是不存在的，如未婚者的配偶姓名、儿童的固定收入等。

###### **缺失值的影响**

- 数据挖掘建模将丢失大量的有用信息。
- 数据挖掘模型所表现出的不确定性更加显著，模型中蕴含的规律更难把握。
- 包含空值的数据会使建模过程陷入混乱，导致不可靠的输出。

###### **缺失值的处理方法**

1. **直接使用含有缺失值的特征**：当仅有少量样本缺失该特征的时候可以尝试使用；
2. **删除含有缺失值的特征**：这个方法一般适用于大多数样本都缺少该特征，且仅包含少量有效值是有效的；
3. **插值补全缺失值**

最常使用的还是第三种插值补全缺失值的做法，这种做法又可以有多种补全方法。

1. **均值/中位数/众数补全**

如果样本属性的距离是可度量的，则使用该属性有效值的平均值来补全；

如果样本属性的距离不可度量，则可以采用众数或者中位数来补全。

2. **同类均值/中位数/众数补全**

对样本进行分类后，根据同类其他样本该属性的均值补全缺失值，当然同第一种方法类似，如果均值不可行，可以尝试众数或者中位数等统计数据来补全。

3. **固定值补全**

利用固定的数值补全缺失的属性值。

4. **建模预测**

利用机器学习方法，将缺失属性作为预测目标进行预测，具体为将样本根据是否缺少该属性分为训练集和测试集，然后采用如回归、决策树等机器学习算法训练模型，再利用训练得到的模型预测测试集中样本的该属性的数值。

这个方法**根本的缺陷是如果其他属性和缺失属性无关，则预测的结果毫无意义；但是若预测结果相当准确，则说明这个缺失属性是没必要纳入数据集中的****；**一般的情况是介于两者之间。

5. **高维映射**

将属性映射到高维空间，采用**独热码编码（one-hot）技术**。将包含 K 个离散取值范围的属性值扩展为 K+1 个属性值，若该属性值缺失，则扩展后的第 K+1 个属性值置为 1。

这种做法是最精确的做法，保留了所有的信息，也未添加任何额外信息，若预处理时把所有的变量都这样处理，会大大增加数据的维度。这样做的好处是**完整保留了原始数据的全部信息、不用考虑缺失值**；缺点是**计算量大大提升，且只有在样本量非常大的时候效果才好**。

6. **多重插补**

多重插补认为待插补的值是随机的，实践上通常是估计出待插补的值，再加上不同的噪声，形成多组可选插补值，根据某种选择依据，选取最合适的插补值。

7. **压缩感知和矩阵补全**

压缩感知通过**利用信号本身所具有的稀疏性，从部分观测样本中回复原信号**。压缩感知分为感知测量和重构恢复两个阶段。

- 感知测量：此阶段对原始信号进行处理以获得稀疏样本表示。常用的手段是傅里叶变换、小波变换、字典学习、稀疏编码等

- 重构恢复：此阶段基于稀疏性从少量观测中恢复原信号。这是**压缩感知的核心**

矩阵补全可以查看知乎上的问题：

https://www.zhihu.com/question/47716840

8. **手动补全**

除了手动补全方法，其他插值补全方法只是将未知值补以我们的主观估计值，不一定完全符合客观事实。在许多情况下，根据对所在领域的理解，手动对缺失值进行插补的效果会更好。但这种方法需要对问题领域有很高的认识和理解，要求比较高，如果缺失数据较多，会比较费时费力。

9. **最近邻补全**

寻找与该样本最接近的样本，使用其该属性数值来补全。

##### 3.1.2 图片数据扩充

对于图片数据，最常遇到的问题就是训练数据不足的问题。

一个模型所能获取的信息一般来源于两个方面，一个是训练数据包含的信息；另一个就是模型的形成过程中（包括构造、学习、推理等），人们提供的先验信息。

而如果训练数据不足，那么模型可以获取的信息就比较少，需要提供更多的先验信息保证模型的效果。先验信息一般作用来两个方面，一是**模型**，如采用特定的内在结构（比如深度学习的不同网络结构）、条件假设或添加其他约束条件（深度学习中体现在损失函数加入不同正则项）；第二就是**数据**，即根据先验知识来调整、变换或者拓展训练数据，让其展现出更多的、更有用的信息。

对于图像数据，如果训练数据不足，导致的后果就是**模型过拟合问题**，即模型在训练样本上的效果不错，但在测试集上的泛化效果很糟糕。过拟合的解决方法可以分为两类：

1. **基于模型的方法**：主要是采用降低过拟合风险的措施，如简化模型（从卷积神经网络变成逻辑回归算法）、添加约束项以缩小假设空间（如 L1、L2等正则化方法）、集成学习、Dropout方法（深度学习常用方法）等；
2. **基于数据的方法**：主要就是**数据扩充**(Data Augmentation)，即根据一些先验知识，在保持特点信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果。具体做法有多种，在保持图像类别不变的前提下，可以对每张图片做如下变换处理。
   - 一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等，这些变换对应着同一个目标在不同角度的观察结果；
   - 对图像中的元素添加噪声扰动，如椒盐噪声、高斯白噪声等；
   - 颜色变换。比如在图像的 RGB 颜色空间进行主成分分析，得到 3 个主成分的特征向量`p1,p2,p3`以及对应的特征值`λ1,λ2,λ3`，然后在每个像素的 RGB 值上添加增量`[p1,p2,p3]*[a1λ1,a2λ2,a3λ3]`，其中`a1,a2,a3`都是均值为 0， 方差较小的高斯分布随机数；
   - 改变图像的亮度、清晰度、对比度、锐度等。

上述数据扩充方法是在图像空间进行变换的，也可以选择先对图像进行特征提取，然后在图像的特征空间进行变换，利用一些通用的数据扩充或者上采样方法，例如 SMOTE。

此外，最近几年一直比较热门的 GAN，生成对抗网络，它的其中一个应用就是生成图片数据，也可以应用于数据扩充。

最后，还有一种方法可以不需要扩充数据，利用迁移学习的做法，也是如今非常常用的一个方法，微调（Finetuning），即借用在大数据集（如 ImageNet）上预训练好的模型，然后在自己的小数据集上进行微调，这是一种简单的迁移学习，同时也可以快速训练一个效果不错的针对目标类别的新模型。

---
### 小结

数据特征缺失和图片数据的不足都是机器学习任务中非常常见的问题，因此需要好好掌握如何处理缺失值，以及扩充图片数据的方法。

---
参考：

- 《百面机器学习》第一章 特征工程
- https://blog.csdn.net/dream_angel_z/article/details/49388733#commentBox
- https://www.cnblogs.com/sherial/archive/2018/03/07/8522405.html
- https://gofisher.github.io/2018/06/22/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/
- https://gofisher.github.io/2018/06/20/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/
- https://juejin.im/post/5b6a44f55188251aa8294b8c
- https://www.zhihu.com/question/47716840

---

欢迎关注我的微信公众号--机器学习与计算机视觉，或者扫描下方的二维码，大家一起交流，学习和进步！

![](https://cai-images-1257823952.cos.ap-beijing.myqcloud.com/qrcode_new.jpg)


#### 往期精彩推荐

##### 学习笔记

- [机器学习入门系列（1）--机器学习概览](https://mp.weixin.qq.com/s/r_UkF_Eys4dTKMH7DNJyTA)
- [[GAN学习系列] 初识GAN](https://mp.weixin.qq.com/s?__biz=MzU5MDY5OTI5MA==&mid=2247483711&idx=1&sn=ead88d5b21e08d9df853b72f31d4b5f4&chksm=fe3b0f4ac94c865cfc243123eb4815539ef2d5babdc8346f79a29b681e55eee5f964bdc61d71&token=1493836032&lang=zh_CN#rd)
- [[GAN学习系列2] GAN的起源](https://mp.weixin.qq.com/s?__biz=MzU5MDY5OTI5MA==&mid=2247483732&idx=1&sn=99cb91edf6fb6da3c7d62132c40b0f62&chksm=fe3b0f21c94c8637a8335998c3fc9d0adf1ac7dea332c2bd45e63707eac6acad8d84c1b3d16d&token=985117826&lang=zh_CN#rd)
- [[GAN学习系列3]采用深度学习和 TensorFlow 实现图片修复(上）](https://mp.weixin.qq.com/s/S_uiSe74Ti6N_u4Y5Fd6Fw)

##### 数学学习笔记

- [程序员的数学笔记1--进制转换](https://mp.weixin.qq.com/s/Sn7V27O77moGCLOpFzEKqg)
- [程序员的数学笔记2--余数](https://mp.weixin.qq.com/s/hv4cWzuca49VHLc92DicZQ)
- [程序员的数学笔记3--迭代法](https://mp.weixin.qq.com/s/uUtK2tTZa_b5jeiTyXYRYg)

##### Github项目 & 资源教程推荐

- [[Github 项目推荐] 一个更好阅读和查找论文的网站](https://mp.weixin.qq.com/s/ImQcGt8guLKZawNLS-_HzA)
- [[资源分享] TensorFlow 官方中文版教程来了](https://mp.weixin.qq.com/s/Si1YaYLfhL1upbjQkvireQ)
- [必读的AI和深度学习博客](https://mp.weixin.qq.com/s/0J2raJqiYsYPqwAV1MALaw)
- [[教程]一份简单易懂的 TensorFlow 教程](https://mp.weixin.qq.com/s/vXIM6Ttw37yzhVB_CvXmCA)
- [[资源]推荐一些Python书籍和教程，入门和进阶的都有！](https://mp.weixin.qq.com/s/jkIQTjM9C3fDvM1c6HwcQg)
