最近会打算每周总结一下学习的内容，主要内容可能是看过的书的一些学习笔记、论文阅读、学习的知识点以及推荐一些文章。

这周的学习包括：

- 推荐系统的知识点整理
- 机器学习的技巧学习
- linux下两台机器的ssh免密登陆方式
- 书籍阅读
- 效率方法

------

### 推荐系统

因为工作方向的原因，从九月份开始工作内容从图像转到了推荐系统，不过推荐系统的内容其实是非常的多，目前也还是在学习，然后也简单做了一个推荐系统知识体系的思维导图，算是作为学习的一个指导方向，会陆续完善这个知识体系：

![](/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/推荐系统/推荐系统知识体系.png)

主要是参考这两本书和极客时间的一门课程：

- 《推荐系统实践》
- 《推荐系统开发实战》
- 极客时间的《推荐系统三十六式》

推荐看的几篇文章有：

- [今日头条、抖音推荐算法原理全文详解！](https://mp.weixin.qq.com/s/7O2tTEsD4bNlpIw4h8iMlQ)
- [电商个性化推荐系统，怎么设计？](https://mp.weixin.qq.com/s/0faZR0CqRrueNklHO62Etg)
- [腾讯信息流内容理解技术实践](https://mp.weixin.qq.com/s/spQfuary3ovCLw5ZgeLH8A)
- 《文章推荐系统》推荐系统系列--jianshu.com/u/ac833cc5146e

------

### 机器学习

分享下[本科生晋升GM记录 & Kaggle比赛进阶技巧分享](https://mp.weixin.qq.com/s/llpex8u9PQNbzxeVXc62hA)中一些不错的调参技巧

#### 优化器的选择

一般选择 Adam，初始学习率是 `3e-4`，据说这是 Adam 最好的初始学习率；另一个选择就是 SGD，随即梯度下降，这个速度会更快，但如何选择学习率就考验调参功力了

#### 学习率策略

如何选择一个合适的学习率策略，即学习率下降的频率和幅度的选择，这个主要影响的当然就是梯度下降是否可以到达全局最小值，而不是陷入局部最小值了。作者推荐的三种策略：

> - ReduceLROnPlateau，patience=4（5），gamma=0.1，这是我常用的一套组合，并不是最好的；
> - StepLR，个人比较喜欢用这个，自己设定好在哪个epoch进行学习率的衰减，个人比较喜欢用的衰减步骤是[5e-4(3e-4), 1e-4, 1e-5, 1e-6]，至于衰减位置，就需要自己有比较好的直觉，或者就是看log调参，对着2.1上训练的valid loss走势，valid loss不收敛了，咱就立刻进行衰减；
> - CosineAnnealingLR+Multi cycle,这个相较于前两个，就不需要太多的调参，可以训练多个cycle，模型可以找到更多的局部最优，一般推荐min_lr=1e-6，至于每个cycle多少epoch这个就说不准了，不同数据不太一样。

#### Finetuning的技巧

微调是指采用一个预训练模型的初始参数，然后在自己的数据集或者新的网络模型上训练得到自己的模型，之所以要使用 finetuning，目的就是更好更快的收敛，并且得到性能更好的模型，由于现在网络模型越来越大，模型的参数都是几十万，上百万，甚至更多，如何设置初始参数就非常重要，好的初始参数当然就可以缩短训练时间，并且获得更佳的性能，而预训练模型就能达到这个目的--提供不错的初始参数选择，当然这里具体微调的方式，也是有以下四种：

- 微调方式一，最常用，只替换掉最后一层 `fc layer`，改成本任务里训练集的类别数目，然后不做其余特殊处理，直接开始训练；

- 微调方式二，在微调一的基础上，freeze backbone 的参数，只更新（预训练）新的fc layer的参数（更新的参数量少，训练更快）到收敛为止，之后再放开所有层的参数，再一起训练；

- 微调方式三，在微调方式二预训练fc layer之后或者直接就是微调方式一，可选择接上**差分学习率**（discriminative learning rates）即更新backbone参数和新fc layer的参数所使用的学习率是不一致的，一般可选择差异10倍，理由是backbone的参数是基于imagenet训练的，参数足够优秀同时泛化性也会更好，所以是希望得到微调即可，不需要太大的变化。

- ```python
  optimizer = torch.optim.Adam([{'params': model.backbone.parameters(), 'lr': 3e-5},
   {'params': model.fc.parameters(), 'lr': 3e-4},   ])
  ```

- 微调方式四，freeze浅层，训练深层（如可以不更新resnet前两个resnet block的参数，只更新其余的参数，一样是为了增强泛化，减少过拟合）。

------

### 编程开发

了解如何实现两台机器的 ssh 免密登陆：

1. 两台机器之间免密登陆的方法，首先是在两台机器分别执行 `ssh-keygen`, 命令出来后，直接按3次回车键，第一次就是默认生成的密钥保存在 `~/.ssh/id_rsa.pub`，然后两次是确认密码
2. 接着在两台机器分别执行命令 `ssh-copy-id -I ~/.ssh/id_rsa.pub root@ip`，这里的ip 是另一台机器的ip，这就是将本机生成的ssh公钥传到另一台机器，并写入其 `~/.ssh/authorized_keys` 文件中
3. 执行完后，`ssh ip` 来试验登陆机器，查看是否设置成功

另外完成这个设置后，两台机器之间的文件传输也是可以不需要输入密码的，也是非常方便了。



------

### 阅读

这周终于是看完《软技能：代码之外的生存指南》，我觉得这确实是一本非常值得程序员看看的书，或者说对于之前比较火的一个话题--怎么做副业，想做副业的也推荐看看这本书，这本书正如书名说的，介绍的代码之外的技能，整本书分为 7 篇，也是 7 个方面的内容，包括：

- **职业**：对自己职业的规划、自由职业者的介绍等
- **自我营销**：提高自己的影响力，打造自己的品牌；
- **学习**：学习方法
- **生产力**：如何提高自己的效率
- **理财**：如何分配每个月的薪水、退休计划、对房地产的投资
- **健身**：一些健身知识的科普
- **精神力**：如何拥有积极的心态、爱情、积极面对失败等

------

### 效率方法

其实一直都在想着怎么提高自己的工作学习效率，之前其实也看过一些文章的介绍，方法包括：

- 设置一个大目标，然后分解成一个个小目标，然后做好月计划、周计划，并且做好总结；
- 番茄工作法，也就是工作学习一段时间，比如30分钟，然后休息5分钟，主要就是提高专注了；

这几个方法都有在使用，不过目前在计划方面会做得不够好，每次总结的时候，都会发现这周的计划似乎太多，导致完成率不到50%，这主要是也是每天的效率有些低。

不过最近，又新学习了一个方法，来自**也大（公众号：也谈钱）**，叫做**每天三件事+记录一件自己开心的事情**，主要就是每天只计划完成 3 件事情即可，数量不多也不会太少，难度也不会太高，每天都能完成也可以保证一个正反馈，提高自己的积极性；

而记录一件开心的事情也是可以让自己在遭遇一些挫折困难或者不够自信的时候，看看自己曾经做过的成功的事情，或者开心的事情，鼓励自己勇于面对挫折、困难或者是失败；

一开始可以先定下一个坚持7天的目标，然后坚持完成7天，则可以继续提高到 14 天，然后再就是一个月，这样就很快能养成这个习惯，目前我的进展是到了 14 天的这个阶段，再坚持 2 天也可以完成坚持 14 天的目标，当然其实这个过程中，也还是有一两天没能完全完成 3 件事情，但我感觉并不要紧，记录下来每件事情的完成程度，或者说原因，明天再继续今天没有完成的事情。

当然每天 3 件事情，其实也是需要根据自己的计划来的，每周的计划依然还是需要尽量量力而行，需要做好减法，只挑选当前紧急重要的事情或者重要但不紧急的事情。



------

